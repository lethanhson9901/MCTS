"""
MCTS Main Entry Point - CLI Interface
"""

import asyncio
import click
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
from rich.panel import Panel
from rich.table import Table
from rich.markdown import Markdown

from backend.config import MCTSConfig, DEFAULT_CONFIG
from backend.core.mcts_orchestrator import MCTSOrchestrator
from backend.core.llm_client import test_llm_connection

# Async click wrapper
def coro(f):
    """Decorator to make click commands work with async functions"""
    def wrapper(*args, **kwargs):
        return asyncio.run(f(*args, **kwargs))
    wrapper.__name__ = f.__name__
    wrapper.__doc__ = f.__doc__
    return wrapper

# Setup console
console = Console()

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('mcts.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def print_banner():
    """In banner chÃ o má»«ng"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘    ğŸ§  MCTS - Multi-Agent Critical Thinking System                           â•‘
â•‘    Há»‡ thá»‘ng TÆ° duy Pháº£n biá»‡n TÄƒng cÆ°á»ng Äa TÃ¡c nhÃ¢n                        â•‘
â•‘                                                                              â•‘
â•‘    Version: 2.0                                                             â•‘
â•‘    Powered by: Gemini 2.5 Pro                                               â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    console.print(banner, style="bold blue")

@click.group()
@click.version_option(version="2.0")
def cli():
    """
    MCTS - Multi-Agent Critical Thinking System
    
    Há»‡ thá»‘ng tÆ° duy pháº£n biá»‡n tÄƒng cÆ°á»ng Ä‘a tÃ¡c nhÃ¢n Ä‘á»ƒ táº¡o ra cÃ¡c Ã½ tÆ°á»Ÿng startup 
    cÃ³ cháº¥t lÆ°á»£ng, tÃ­nh kháº£ thi vÃ  tiá»m nÄƒng thÃ nh cÃ´ng cao.
    """
    print_banner()

@cli.command()
@click.argument('message')
@coro
async def quick(message):
    """
    ğŸš€ Quick mode - Há»i nhanh vÃ  nháº­n káº¿t quáº£ ngay
    
    MESSAGE: CÃ¢u há»i hoáº·c yÃªu cáº§u
    
    VÃ­ dá»¥:
    python main.py quick "AI trends 2024?"
    python main.py quick "Ã tÆ°á»Ÿng app cho sinh viÃªn"
    """
    
    if not message:
        console.print("âŒ Cáº§n cÃ³ cÃ¢u há»i. VÃ­ dá»¥: python main.py quick 'AI trends 2024?'", style="red")
        return
    
    try:
        from backend.core.dynamic_processor import process_user_message
        
        console.print(f"âš¡ Quick processing: {message}", style="yellow")
        
        response = await process_user_message(message)
        
        console.print(f"\nğŸ¤– {response.content}", style="white")
        
        if response.suggestions:
            console.print(f"\nğŸ’¡ {response.suggestions[0]}", style="dim cyan")
            
    except Exception as e:
        console.print(f"âŒ Error: {str(e)}", style="red")

@cli.command()
@click.option('--config', '-c', help='ÄÆ°á»ng dáº«n Ä‘áº¿n file config JSON')
@click.option('--data-sources', '-d', multiple=True, help='ÄÆ°á»ng dáº«n Ä‘áº¿n data sources')
@click.option('--focus-areas', '-f', multiple=True, help='LÄ©nh vá»±c táº­p trung (vÃ­ dá»¥: AI/ML, SaaS, Fintech)')
@click.option('--start-date', help='NgÃ y báº¯t Ä‘áº§u phÃ¢n tÃ­ch (YYYY-MM-DD)')
@click.option('--end-date', help='NgÃ y káº¿t thÃºc phÃ¢n tÃ­ch (YYYY-MM-DD)')
@click.option('--output-dir', '-o', help='ThÆ° má»¥c output')
@click.option('--max-analysis-loops', type=int, help='Sá»‘ vÃ²ng láº·p phÃ¢n tÃ­ch tá»‘i Ä‘a')
@click.option('--max-idea-loops', type=int, help='Sá»‘ vÃ²ng láº·p Ã½ tÆ°á»Ÿng tá»‘i Ä‘a')
@click.option('--verbose', '-v', is_flag=True, help='Hiá»ƒn thá»‹ log chi tiáº¿t')
@coro
async def analyze(config, data_sources, focus_areas, start_date, end_date, 
                 output_dir, max_analysis_loops, max_idea_loops, verbose):
    """
    Cháº¡y phÃ¢n tÃ­ch MCTS Ä‘áº§y Ä‘á»§
    
    VÃ­ dá»¥:
    python main.py analyze -d data/reddit.json -d data/hn.json -f "AI/ML" -f "SaaS"
    """
    
    try:
        # Load config
        mcts_config = load_config(config, {
            'output_dir': output_dir,
            'max_analysis_loops': max_analysis_loops,
            'max_idea_loops': max_idea_loops
        })
        
        if verbose:
            logging.getLogger().setLevel(logging.DEBUG)
        
        # Validate data sources
        if not data_sources:
            console.print("âŒ Cáº§n Ã­t nháº¥t má»™t data source", style="red")
            return
        
        # Load data sources
        loaded_data_sources = load_data_sources(data_sources)
        
        # Set focus areas
        if not focus_areas:
            focus_areas = ["Technology", "Market_Analysis", "Business_Model"]
        
        # Set timeframe
        timeframe = {
            "start": start_date or "2024-01-01",
            "end": end_date or datetime.now().strftime("%Y-%m-%d")
        }
        
        console.print(f"\nğŸš€ Báº¯t Ä‘áº§u phÃ¢n tÃ­ch MCTS...", style="bold green")
        console.print(f"ğŸ“Š Data sources: {len(loaded_data_sources)}")
        console.print(f"ğŸ¯ Focus areas: {', '.join(focus_areas)}")
        console.print(f"ğŸ“… Timeframe: {timeframe['start']} Ä‘áº¿n {timeframe['end']}")
        
        # Test LLM connection first
        console.print("\nğŸ” Kiá»ƒm tra káº¿t ná»‘i LLM...", style="yellow")
        connection_ok = await test_llm_connection(mcts_config.llm)
        
        if not connection_ok:
            console.print("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i vá»›i LLM API", style="red")
            return
        
        console.print("âœ… Káº¿t ná»‘i LLM thÃ nh cÃ´ng", style="green")
        
        # Run MCTS analysis vá»›i progress tracking
        async with MCTSOrchestrator(mcts_config) as orchestrator:
            
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TaskProgressColumn(),
                console=console
            ) as progress:
                
                # Create progress task
                task = progress.add_task("Äang cháº¡y MCTS Analysis...", total=100)
                
                # Start analysis
                analysis_task = asyncio.create_task(
                    orchestrator.run_full_analysis(
                        data_sources=loaded_data_sources,
                        timeframe=timeframe,
                        focus_areas=list(focus_areas)
                    )
                )
                
                # Update progress periodically
                while not analysis_task.done():
                    status = orchestrator.get_session_status()
                    if status.get("status") != "no_active_session":
                        completion = status.get("completion_percentage", 0)
                        phase = status.get("current_phase", "unknown")
                        progress.update(task, completed=completion, description=f"Phase: {phase}")
                    
                    await asyncio.sleep(2)
                
                # Get result
                session = await analysis_task
                progress.update(task, completed=100, description="HoÃ n thÃ nh!")
        
        # Display results
        display_results(session)
        
    except Exception as e:
        console.print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch: {str(e)}", style="red")
        logger.error(f"Analysis error: {str(e)}", exc_info=True)

@cli.command()
@click.option('--config', '-c', help='ÄÆ°á»ng dáº«n Ä‘áº¿n file config JSON')
def test_connection(config):
    """
    Kiá»ƒm tra káº¿t ná»‘i vá»›i LLM API
    """
    
    try:
        mcts_config = load_config(config)
        
        console.print("ğŸ” Äang kiá»ƒm tra káº¿t ná»‘i LLM API...", style="yellow")
        
        success = asyncio.run(test_llm_connection(mcts_config.llm))
        
        if success:
            console.print("âœ… Káº¿t ná»‘i LLM thÃ nh cÃ´ng!", style="green")
            console.print(f"URL: {mcts_config.llm.url}")
            console.print(f"Model: {mcts_config.llm.model}")
        else:
            console.print("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i vá»›i LLM API", style="red")
            console.print("Vui lÃ²ng kiá»ƒm tra:")
            console.print("- URL cÃ³ Ä‘Ãºng khÃ´ng")
            console.print("- API key cÃ³ há»£p lá»‡ khÃ´ng") 
            console.print("- Service cÃ³ Ä‘ang cháº¡y khÃ´ng")
            
    except Exception as e:
        console.print(f"âŒ Lá»—i: {str(e)}", style="red")

@cli.command()
@click.argument('session_dir', type=click.Path(exists=True))
def show_results(session_dir):
    """
    Hiá»ƒn thá»‹ káº¿t quáº£ tá»« session Ä‘Ã£ lÆ°u
    
    SESSION_DIR: ThÆ° má»¥c chá»©a káº¿t quáº£ session
    """
    
    try:
        session_path = Path(session_dir)
        
        # Load session summary
        summary_file = session_path / "session_summary.json"
        if not summary_file.exists():
            console.print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file session_summary.json trong {session_dir}", style="red")
            return
        
        with open(summary_file, 'r', encoding='utf-8') as f:
            session_data = json.load(f)
        
        # Display results
        display_session_summary(session_data)
        
        # Display analysis results if available
        analysis_file = session_path / "analysis_results.md"
        if analysis_file.exists():
            console.print("\nğŸ“Š Káº¾T QUáº¢ PHÃ‚N TÃCH:", style="bold blue")
            with open(analysis_file, 'r', encoding='utf-8') as f:
                content = f.read()
                console.print(Markdown(content[:2000] + "..." if len(content) > 2000 else content))
        
        # Display ideas results if available
        ideas_file = session_path / "ideas_results.md"
        if ideas_file.exists():
            console.print("\nğŸ’¡ Káº¾T QUáº¢ Ã TÆ¯á»NG:", style="bold blue")
            with open(ideas_file, 'r', encoding='utf-8') as f:
                content = f.read()
                console.print(Markdown(content[:2000] + "..." if len(content) > 2000 else content))
                
    except Exception as e:
        console.print(f"âŒ Lá»—i Ä‘á»c káº¿t quáº£: {str(e)}", style="red")

@cli.command()
def create_sample_config():
    """
    Táº¡o file config máº«u
    """
    
    sample_config = {
        "llm": {
            "url": "http://localhost:8000/v1/chat/completions",
            "model": "gemini-2.5-pro",
            "api_key": "sk-1234",
            "max_tokens": 4000,
            "temperature": 0.7,
            "timeout": 60
        },
        "max_analysis_loops": 3,
        "max_idea_loops": 4,
        "quality_threshold": 9.0,
        "improvement_threshold": 0.05,
        "red_flag_threshold": 3.0,
        "weights": {
            "tinh_kha_thi": 2.0,
            "tiem_nang_thi_truong": 2.5,
            "tinh_sang_tao": 1.5,
            "mo_hinh_kinh_doanh": 2.0,
            "loi_the_canh_tranh": 1.8,
            "rui_ro_ky_thuat": 1.5,
            "dau_tu_ban_dau": 1.2
        },
        "adversarial_roles": ["VC", "Ká»¹_sÆ°", "Äá»‘i_thá»§"],
        "enable_external_validation": True,
        "search_timeout": 30,
        "log_level": "INFO",
        "save_intermediate_results": True,
        "output_dir": "results"
    }
    
    config_file = "mcts_config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(sample_config, f, ensure_ascii=False, indent=2)
    
    console.print(f"âœ… ÄÃ£ táº¡o file config máº«u: {config_file}", style="green")
    console.print("Báº¡n cÃ³ thá»ƒ chá»‰nh sá»­a file nÃ y vÃ  sá»­ dá»¥ng vá»›i tÃ¹y chá»n --config")

@cli.command()
@coro
async def chat():
    """
    Báº¯t Ä‘áº§u interactive chat session vá»›i MCTS AI
    
    Mode nÃ y cho phÃ©p báº¡n:
    - Há»i báº¥t ká»³ cÃ¢u há»i nÃ o vá» startup/business
    - YÃªu cáº§u phÃ¢n tÃ­ch dá»¯ liá»‡u real-time
    - Táº¡o Ã½ tÆ°á»Ÿng startup tá»« input tá»± do
    - TÆ°Æ¡ng tÃ¡c natural language hoÃ n toÃ n
    """
    
    try:
        from backend.core.dynamic_processor import start_interactive_session
        await start_interactive_session()
        
    except Exception as e:
        console.print(f"âŒ Lá»—i khá»Ÿi táº¡o chat session: {str(e)}", style="red")

@cli.command()
@click.argument('message', required=False)
@click.option('--config', '-c', help='ÄÆ°á»ng dáº«n Ä‘áº¿n file config JSON')
@coro
async def ask(message, config):
    """
    Há»i MCTS má»™t cÃ¢u há»i hoáº·c yÃªu cáº§u cá»¥ thá»ƒ
    
    MESSAGE: CÃ¢u há»i hoáº·c yÃªu cáº§u (náº¿u khÃ´ng cÃ³ sáº½ prompt)
    
    VÃ­ dá»¥:
    python main.py ask "PhÃ¢n tÃ­ch xu hÆ°á»›ng AI startup 2024"
    python main.py ask "Táº¡o Ã½ tÆ°á»Ÿng fintech cho Gen Z"
    python main.py ask "So sÃ¡nh SaaS vs PaaS market"
    """
    
    try:
        from backend.core.dynamic_processor import process_user_message
        
        # Load config
        mcts_config = load_config(config)
        
        # Get message if not provided
        if not message:
            message = click.prompt("ğŸ’¬ Báº¡n muá»‘n há»i gÃ¬?", type=str)
        
        if not message.strip():
            console.print("âŒ Cáº§n cÃ³ cÃ¢u há»i hoáº·c yÃªu cáº§u", style="red")
            return
        
        console.print(f"\nğŸ¤” Äang xá»­ lÃ½: {message}", style="yellow")
        
        # Process vá»›i dynamic processor
        response = await process_user_message(message, mcts_config)
        
        # Display response
        console.print("\n" + "="*60, style="blue")
        console.print("ğŸ¤– MCTS AI Response:", style="bold blue")
        console.print("="*60, style="blue")
        console.print(f"\n{response.content}", style="white")
        
        # Show metadata
        if response.success:
            console.print(f"\nâœ… Response Type: {response.response_type}", style="green")
        else:
            console.print(f"\nâŒ Response Type: {response.response_type}", style="red")
        
        # Show suggestions
        if response.suggestions:
            console.print("\nğŸ’¡ Gá»£i Ã½ tiáº¿p theo:", style="cyan")
            for i, suggestion in enumerate(response.suggestions, 1):
                console.print(f"   {i}. {suggestion}", style="dim cyan")
        
        # Show follow-up questions
        if response.follow_up_questions:
            console.print("\nâ“ CÃ¢u há»i tiáº¿p theo:", style="magenta")
            for i, question in enumerate(response.follow_up_questions, 1):
                console.print(f"   {i}. {question}", style="dim magenta")
        
        # Session info if available
        if response.metadata.get("session_id"):
            session_id = response.metadata["session_id"]
            console.print(f"\nğŸ’¾ Session ID: {session_id}", style="dim white")
            console.print(f"ğŸ“ Results saved to: {DEFAULT_CONFIG.output_dir}/{session_id}", style="dim white")
        
    except Exception as e:
        console.print(f"âŒ Lá»—i xá»­ lÃ½ request: {str(e)}", style="red")
        logger.error(f"Ask command error: {str(e)}", exc_info=True)

@cli.command()
def create_sample_data():
    """
    Táº¡o file dá»¯ liá»‡u máº«u Ä‘á»ƒ test (legacy command)
    
    LÆ°u Ã½: Vá»›i dynamic mode má»›i, báº¡n cÃ³ thá»ƒ directly input
    data mÃ  khÃ´ng cáº§n sample files. Sá»­ dá»¥ng 'chat' hoáº·c 'ask'.
    """
    
    sample_data_sources = [
        {
            "type": "reddit",
            "description": "Dá»¯ liá»‡u tá»« r/startups vá» xu hÆ°á»›ng startup 2024",
            "content": """
            NgÆ°á»i dÃ¹ng Ä‘ang tháº£o luáº­n vá» cÃ¡c xu hÆ°á»›ng startup ná»•i báº­t:
            
            1. AI/ML Applications:
            - Nhiá»u startup Ä‘ang tÃ­ch há»£p AI Ä‘á»ƒ cáº£i thiá»‡n user experience
            - Äáº·c biá»‡t quan tÃ¢m Ä‘áº¿n generative AI vÃ  automation
            - Pain point: Chi phÃ­ inference cao, cáº§n optimize models
            
            2. SaaS Solutions:
            - Micro-SaaS Ä‘ang trending vá»›i focus vÃ o niche markets
            - Integration platforms Ä‘Æ°á»£c quan tÃ¢m nhiá»u
            - Pain point: Customer acquisition cost ngÃ y cÃ ng cao
            
            3. Fintech Innovations:
            - Payment solutions cho emerging markets
            - DeFi tools cho retail users
            - Pain point: Regulatory compliance phá»©c táº¡p
            
            Top comments cho tháº¥y entrepreneurs quan tÃ¢m:
            - Market validation strategies
            - Product-market fit indicators  
            - Funding landscape thay Ä‘á»•i
            """
        },
        {
            "type": "hackernews",
            "description": "Tháº£o luáº­n cÃ´ng nghá»‡ tá»« Hacker News",
            "content": """
            CÃ¡c chá»§ Ä‘á» hot trÃªn HN gáº§n Ä‘Ã¢y:
            
            Technology Trends:
            - WebAssembly adoption Ä‘ang tÄƒng máº¡nh
            - Edge computing solutions
            - Privacy-first development approaches
            - Open source AI models
            
            Developer Pain Points:
            - Tool fatigue - quÃ¡ nhiá»u frameworks/tools
            - Performance optimization challenges
            - Security concerns with new technologies
            - Developer experience (DevEx) quan trá»ng hÆ¡n
            
            Market Observations:
            - Big Tech layoffs táº¡o cÆ¡ há»™i cho startups
            - Remote work tools evolution
            - Climate tech solutions Ä‘Æ°á»£c quan tÃ¢m
            - Web3 infrastructure maturing
            """
        },
        {
            "type": "product_hunt",
            "description": "Sáº£n pháº©m má»›i launch trÃªn Product Hunt",
            "content": """
            Top sáº£n pháº©m Ä‘Æ°á»£c launch gáº§n Ä‘Ã¢y:
            
            AI-Powered Tools:
            - Writing assistants vá»›i specialized domains
            - Design automation tools
            - Code review vÃ  optimization platforms
            - Voice synthesis vÃ  conversion tools
            
            Productivity Solutions:
            - Team collaboration platforms
            - Project management vá»›i AI insights
            - Time tracking vÃ  productivity analytics
            - Meeting automation tools
            
            Developer Tools:
            - No-code/low-code platforms
            - API management solutions
            - Database optimization tools
            - Testing automation frameworks
            
            Market Patterns:
            - Focus on vertical solutions thay vÃ¬ horizontal
            - Integration-first approach
            - Mobile-first design
            - Subscription model dominance
            """
        }
    ]
    
    # Create data directory
    Path("sample_data").mkdir(exist_ok=True)
    
    # Save individual data sources
    for i, source in enumerate(sample_data_sources):
        filename = f"sample_data/{source['type']}_data.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(source, f, ensure_ascii=False, indent=2)
        
        console.print(f"âœ… ÄÃ£ táº¡o: {filename}")
    
    console.print("\nğŸ“ Äá»ƒ sá»­ dá»¥ng dá»¯ liá»‡u máº«u, cháº¡y:")
    console.print("python main.py analyze -d sample_data/reddit_data.json -d sample_data/hackernews_data.json -d sample_data/product_hunt_data.json -f 'AI/ML' -f 'SaaS' -f 'Fintech'")

@cli.command()
@click.argument('prompt', required=True)
@click.option('--analysis-loops', type=int, default=3, help='Sá»‘ vÃ²ng láº·p phÃ¢n tÃ­ch (X)')
@click.option('--idea-loops', type=int, default=3, help='Sá»‘ vÃ²ng láº·p Ã½ tÆ°á»Ÿng (Y)')
@click.option('--config', '-c', help='ÄÆ°á»ng dáº«n Ä‘áº¿n file config JSON')
@click.option('--no-esv', is_flag=True, help='Táº¯t ESV validation')
@click.option('--output', '-o', help='ThÆ° má»¥c xuáº¥t káº¿t quáº£ (ghi Ä‘Ã¨)')
@coro
async def pipeline(prompt, analysis_loops, idea_loops, config, no_esv, output):
    """
    Cháº¡y FULL PIPELINE tá»« input tá»± do: phÃ¢n tÃ­ch â†’ thá»­ lá»­a â†’ tá»•ng há»£p â†’ láº·p â†’ bÃ¡o cÃ¡o.

    VÃ­ dá»¥:
    python main.py pipeline "PhÃ¢n tÃ­ch thá»‹ trÆ°á»ng fintech VN vÃ  táº¡o Ã½ tÆ°á»Ÿng" --analysis-loops 2 --idea-loops 3
    """
    from backend.core.reporting import generate_full_report_md

    # Load vÃ  tÃ¹y biáº¿n config
    cfg = load_config(config)
    cfg.max_analysis_loops = analysis_loops
    cfg.max_idea_loops = idea_loops
    if no_esv:
        cfg.enable_external_validation = False
    if output:
        cfg.output_dir = output

    console.print("\nğŸš€ Äang cháº¡y FULL PIPELINE...", style="bold green")
    console.print(f"ğŸ§ª VÃ²ng phÃ¢n tÃ­ch: {cfg.max_analysis_loops} | ğŸ’¡ VÃ²ng Ã½ tÆ°á»Ÿng: {cfg.max_idea_loops}")

    # Táº¡o data source tá»« prompt tá»± do
    data_sources = [{
        "type": "user_prompt",
        "description": "Input tá»± do cá»§a ngÆ°á»i dÃ¹ng",
        "content": prompt
    }]

    timeframe = {
        "start": datetime.now().strftime('%Y-%m-%d'),
        "end": datetime.now().strftime('%Y-%m-%d')
    }

    focus_areas = []  # Ä‘á»ƒ orchestrator tá»± phÃ¡t hiá»‡n

    async with MCTSOrchestrator(cfg) as orchestrator:
        session = await orchestrator.run_full_analysis(
            data_sources=data_sources,
            timeframe=timeframe,
            focus_areas=focus_areas
        )

        # Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p Markdown
        base_output_dir = f"{cfg.output_dir}/{session.session_id}"
        report_md = generate_full_report_md(session, base_output_dir)
        report_path = f"{base_output_dir}/final_report.md"

        # Ghi ra tá»‡p
        from pathlib import Path as _Path
        _Path(base_output_dir).mkdir(parents=True, exist_ok=True)
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_md)

        console.print("\nâœ… HoÃ n thÃ nh FULL PIPELINE", style="green")
        console.print(f"ğŸ“‚ ThÆ° má»¥c káº¿t quáº£: {base_output_dir}")
        console.print(f"ğŸ“„ BÃ¡o cÃ¡o cuá»‘i: {report_path}")
        console.print("\nGá»“m:")
        console.print("- analysis_results.md (phÃ¢n tÃ­ch cuá»‘i)")
        console.print("- ideas_results.md (Ã½ tÆ°á»Ÿng cuá»‘i)")
        console.print("- final_deliverables.json (tá»•ng há»£p sá»‘ liá»‡u)")
        console.print("- final_report.md (bÃ¡o cÃ¡o Markdown Ä‘áº§y Ä‘á»§)")

def load_config(config_file: str = None, overrides: Dict[str, Any] = None) -> MCTSConfig:
    """Load configuration tá»« file hoáº·c sá»­ dá»¥ng default"""
    
    if config_file and Path(config_file).exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            config_data = json.load(f)
        
        # Apply overrides
        if overrides:
            for key, value in overrides.items():
                if value is not None:
                    config_data[key] = value
        
        # Create MCTSConfig tá»« dict (would need to implement proper deserialization)
        # For now, just use default vÃ  apply specific overrides
        config = DEFAULT_CONFIG
        
        if overrides:
            if 'output_dir' in overrides and overrides['output_dir']:
                config.output_dir = overrides['output_dir']
            if 'max_analysis_loops' in overrides and overrides['max_analysis_loops']:
                config.max_analysis_loops = overrides['max_analysis_loops']
            if 'max_idea_loops' in overrides and overrides['max_idea_loops']:
                config.max_idea_loops = overrides['max_idea_loops']
        
        return config
    else:
        return DEFAULT_CONFIG

def load_data_sources(data_source_paths: List[str]) -> List[Dict[str, Any]]:
    """Load data sources tá»« files"""
    
    data_sources = []
    
    for path in data_source_paths:
        try:
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                data_sources.append(data)
                console.print(f"âœ… ÄÃ£ load: {path}")
        except Exception as e:
            console.print(f"âŒ Lá»—i load {path}: {str(e)}", style="red")
    
    return data_sources

def display_results(session):
    """Hiá»ƒn thá»‹ káº¿t quáº£ session"""
    
    console.print("\n" + "="*80, style="bold blue")
    console.print("ğŸ‰ Káº¾T QUáº¢ PHÃ‚N TÃCH MCTS", style="bold blue", justify="center")
    console.print("="*80, style="bold blue")
    
    # Session summary
    summary_table = Table(title="ğŸ“Š TÃ³m táº¯t Session")
    summary_table.add_column("ThÃ´ng tin", style="cyan")
    summary_table.add_column("GiÃ¡ trá»‹", style="white")
    
    summary_table.add_row("Session ID", session.session_id)
    summary_table.add_row("Thá»i gian báº¯t Ä‘áº§u", session.start_time.strftime("%Y-%m-%d %H:%M:%S"))
    summary_table.add_row("Thá»i gian káº¿t thÃºc", session.end_time.strftime("%Y-%m-%d %H:%M:%S") if session.end_time else "Äang cháº¡y")
    summary_table.add_row("VÃ²ng láº·p phÃ¢n tÃ­ch", str(session.analysis_iteration))
    summary_table.add_row("VÃ²ng láº·p Ã½ tÆ°á»Ÿng", str(session.ideas_iteration))
    summary_table.add_row("Tráº¡ng thÃ¡i", session.current_phase.value)
    
    console.print(summary_table)
    
    # Quality metrics
    if session.final_deliverables:
        quality_metrics = session.final_deliverables.get("quality_metrics", {})
        
        if quality_metrics:
            console.print("\nğŸ“ˆ CHáº¤T LÆ¯á»¢NG Káº¾T QUáº¢", style="bold green")
            
            analysis_metrics = quality_metrics.get("analysis_phase", {})
            ideas_metrics = quality_metrics.get("ideas_phase", {})
            
            metrics_table = Table()
            metrics_table.add_column("Phase", style="cyan")
            metrics_table.add_column("Äiá»ƒm cuá»‘i", style="white")
            metrics_table.add_column("Cáº£i thiá»‡n", style="green")
            metrics_table.add_column("Äiá»ƒm TB", style="white")
            
            if analysis_metrics:
                metrics_table.add_row(
                    "Analysis",
                    f"{analysis_metrics.get('final_score', 0):.2f}/10",
                    f"+{analysis_metrics.get('improvement', 0):.2f}",
                    f"{analysis_metrics.get('average_score', 0):.2f}/10"
                )
            
            if ideas_metrics:
                metrics_table.add_row(
                    "Ideas",
                    f"{ideas_metrics.get('final_score', 0):.2f}/10",
                    f"+{ideas_metrics.get('improvement', 0):.2f}",
                    f"{ideas_metrics.get('average_score', 0):.2f}/10"
                )
            
            console.print(metrics_table)
        
        # Recommendations
        recommendations = session.final_deliverables.get("recommendations", [])
        if recommendations:
            console.print("\nğŸ’¡ KHUYáº¾N NGHá»Š", style="bold yellow")
            for rec in recommendations:
                console.print(f"  {rec}")
    
    # Output location
    if hasattr(session, 'session_id'):
        output_path = f"{DEFAULT_CONFIG.output_dir}/{session.session_id}"
        console.print(f"\nğŸ’¾ Káº¿t quáº£ chi tiáº¿t Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_path}", style="bold cyan")
        console.print(f"ğŸ“„ Äá»ƒ xem káº¿t quáº£: python main.py show-results {output_path}")

def display_session_summary(session_data):
    """Hiá»ƒn thá»‹ tÃ³m táº¯t session tá»« saved data"""
    
    console.print(Panel.fit(
        f"Session: {session_data.get('session_id', 'Unknown')}",
        title="ğŸ“Š Session Summary",
        border_style="blue"
    ))
    
    # Create summary table
    table = Table(show_header=True)
    table.add_column("Metric", style="cyan")
    table.add_column("Value", style="white")
    
    table.add_row("Start Time", session_data.get('start_time', 'Unknown'))
    table.add_row("End Time", session_data.get('end_time', 'Unknown'))
    table.add_row("Current Phase", session_data.get('current_phase', 'Unknown'))
    table.add_row("Analysis Iterations", str(session_data.get('analysis_iteration', 0)))
    table.add_row("Ideas Iterations", str(session_data.get('ideas_iteration', 0)))
    table.add_row("User Checkpoints", str(len(session_data.get('user_checkpoints', []))))
    
    console.print(table)

# Async commands Ä‘Ã£ Ä‘Æ°á»£c wrapped vá»›i @coro decorator

if __name__ == "__main__":
    cli()
